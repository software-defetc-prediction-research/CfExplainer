# CfExplainer
  CfExplainer, a rule-based method for explainable defect prediction, the explanations of the proposed approach can enhance the model credibility and help guide developers in fixing defects and reducing the risk of introducing them.
# DataSet
  we selected Openstack and Qt from the open source software projects provided by McIntosh and Kamei(https://github.com/software-rebels/JITMovingTarget)
# CfExplainer Method
  1. Generating synthetic instances：① Similar Instance Selection: Feature normalisation, Calculate the instance similarity score, Select top-N similar instances
     ② Counterfactual generation of synthetic instances
  2. Synthetic Instance Prediction
  3. Building Local Model
     ① Rule Generation(Apriori)
     ② Rule Ranking
     ③ Rule Pruning
     ④ Multi-Rule Prediction
  4. Rules Explanation
# Research Questions
  1. RQ1: How similar are the synthetic instances generated by CfExplainer to the instances to be explained?
  2. RQ2: Does our CfExplainer have higher local model fitness than other baseline methods?
  3. RQ3: How reliable is the CfExplainer explanation?
# experiments
  local model：The local models of CfExplainer, PyExplainer and LIME are weighted class association rules（rule_minning.py）, RuleFit(rule_fit.py) , K-Lasso(K-lasso.py) respectively
  weighted class association rules：1、Rule Generation(Apriori)：def apriori_generate_rule（*）；2、Rule Ranking；def rank_rule(*）；3、Rule Pruning：def remove_conflict_rule(*），def               remove_redundant_rule(*）；4、Multi-Rule Prediction：def rules_predict(*）
  Instance generation method：Random generation, cross-mutation, counterfactual generation
  

